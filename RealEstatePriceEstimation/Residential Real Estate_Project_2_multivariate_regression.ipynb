{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore multivariate regression and feature engineering.\n",
    "\n",
    "In this notebook you will use data on house sales to predict prices using multiple regression. You will:\n",
    "* Do some feature engineering\n",
    "* Use built-in python functions to compute the regression weights (coefficients/parameters)\n",
    "* Given the regression weights, predictors and outcome write a function to compute the Residual Sum of Squares\n",
    "* Look at coefficients and interpret their meanings\n",
    "* Evaluate multiple models via RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sale data, split data into training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SALE TYPE</th>\n",
       "      <th>SOLD DATE</th>\n",
       "      <th>PROPERTY TYPE</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE OR PROVINCE</th>\n",
       "      <th>ZIP OR POSTAL CODE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>BEDS</th>\n",
       "      <th>BATHS</th>\n",
       "      <th>...</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>NEXT OPEN HOUSE START TIME</th>\n",
       "      <th>NEXT OPEN HOUSE END TIME</th>\n",
       "      <th>URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>MLS#</th>\n",
       "      <th>FAVORITE</th>\n",
       "      <th>INTERESTED</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAST SALE</td>\n",
       "      <td>March-13-2015</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>1157 S Stelling Rd</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.redfin.com/CA/Cupertino/1157-S-Stel...</td>\n",
       "      <td>MLSListings</td>\n",
       "      <td>ML81448134</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.303816</td>\n",
       "      <td>-122.041727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAST SALE</td>\n",
       "      <td>April-17-2018</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>10340 Las Ondas Way</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>2798000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.redfin.com/CA/Cupertino/10340-Las-O...</td>\n",
       "      <td>MLSListings</td>\n",
       "      <td>ML81695379</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.317957</td>\n",
       "      <td>-122.024231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAST SALE</td>\n",
       "      <td>February-4-2019</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>1035 W Homestead Rd</td>\n",
       "      <td>SUNNYVALE</td>\n",
       "      <td>CA</td>\n",
       "      <td>94087.0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.redfin.com/CA/Sunnyvale/1035-W-Home...</td>\n",
       "      <td>MLSListings</td>\n",
       "      <td>ML81733182</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.337792</td>\n",
       "      <td>-122.056622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAST SALE</td>\n",
       "      <td>July-9-2018</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>11030 Firethorne Dr</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>1307000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.redfin.com/CA/Cupertino/11030-Firet...</td>\n",
       "      <td>MLSListings</td>\n",
       "      <td>ML81708624</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.338270</td>\n",
       "      <td>-122.032713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAST SALE</td>\n",
       "      <td>July-12-2019</td>\n",
       "      <td>Single Family Residential</td>\n",
       "      <td>10590 S Tantau Ave</td>\n",
       "      <td>CUPERTINO</td>\n",
       "      <td>CA</td>\n",
       "      <td>95014.0</td>\n",
       "      <td>2090000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Sold</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.redfin.com/CA/Cupertino/10590-S-Tan...</td>\n",
       "      <td>MLSListings</td>\n",
       "      <td>ML81753390</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>37.314344</td>\n",
       "      <td>-122.007310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SALE TYPE        SOLD DATE              PROPERTY TYPE              ADDRESS  \\\n",
       "0  PAST SALE    March-13-2015  Single Family Residential   1157 S Stelling Rd   \n",
       "1  PAST SALE    April-17-2018  Single Family Residential  10340 Las Ondas Way   \n",
       "2  PAST SALE  February-4-2019  Single Family Residential  1035 W Homestead Rd   \n",
       "3  PAST SALE      July-9-2018                  Townhouse  11030 Firethorne Dr   \n",
       "4  PAST SALE     July-12-2019  Single Family Residential   10590 S Tantau Ave   \n",
       "\n",
       "        CITY STATE OR PROVINCE  ZIP OR POSTAL CODE      PRICE  BEDS  BATHS  \\\n",
       "0  CUPERTINO                CA             95014.0  1500000.0   3.0    2.0   \n",
       "1  CUPERTINO                CA             95014.0  2798000.0   4.0    2.5   \n",
       "2  SUNNYVALE                CA             94087.0  2200000.0   4.0    3.0   \n",
       "3  CUPERTINO                CA             95014.0  1307000.0   2.0    2.5   \n",
       "4  CUPERTINO                CA             95014.0  2090000.0   3.0    3.0   \n",
       "\n",
       "   ... STATUS  NEXT OPEN HOUSE START TIME  NEXT OPEN HOUSE END TIME  \\\n",
       "0  ...   Sold                         NaN                       NaN   \n",
       "1  ...   Sold                         NaN                       NaN   \n",
       "2  ...   Sold                         NaN                       NaN   \n",
       "3  ...   Sold                         NaN                       NaN   \n",
       "4  ...   Sold                         NaN                       NaN   \n",
       "\n",
       "   URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)  \\\n",
       "0  http://www.redfin.com/CA/Cupertino/1157-S-Stel...                                            \n",
       "1  http://www.redfin.com/CA/Cupertino/10340-Las-O...                                            \n",
       "2  http://www.redfin.com/CA/Sunnyvale/1035-W-Home...                                            \n",
       "3  http://www.redfin.com/CA/Cupertino/11030-Firet...                                            \n",
       "4  http://www.redfin.com/CA/Cupertino/10590-S-Tan...                                            \n",
       "\n",
       "        SOURCE        MLS#  FAVORITE INTERESTED   LATITUDE   LONGITUDE  \n",
       "0  MLSListings  ML81448134         N          Y  37.303816 -122.041727  \n",
       "1  MLSListings  ML81695379         N          Y  37.317957 -122.024231  \n",
       "2  MLSListings  ML81733182         N          Y  37.337792 -122.056622  \n",
       "3  MLSListings  ML81708624         N          Y  37.338270 -122.032713  \n",
       "4  MLSListings  ML81753390         N          Y  37.314344 -122.007310  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2450 entries, 0 to 2449\n",
      "Data columns (total 27 columns):\n",
      "SALE TYPE                                                                                     2450 non-null object\n",
      "SOLD DATE                                                                                     965 non-null object\n",
      "PROPERTY TYPE                                                                                 2450 non-null object\n",
      "ADDRESS                                                                                       2438 non-null object\n",
      "CITY                                                                                          2444 non-null object\n",
      "STATE OR PROVINCE                                                                             2450 non-null object\n",
      "ZIP OR POSTAL CODE                                                                            2443 non-null float64\n",
      "PRICE                                                                                         1864 non-null float64\n",
      "BEDS                                                                                          2311 non-null float64\n",
      "BATHS                                                                                         2306 non-null float64\n",
      "LOCATION                                                                                      965 non-null object\n",
      "SQUARE FEET                                                                                   2361 non-null float64\n",
      "LOT SIZE                                                                                      2175 non-null float64\n",
      "YEAR BUILT                                                                                    2373 non-null float64\n",
      "DAYS ON MARKET                                                                                965 non-null float64\n",
      "$/SQUARE FEET                                                                                 1820 non-null float64\n",
      "HOA/MONTH                                                                                     402 non-null float64\n",
      "STATUS                                                                                        1551 non-null object\n",
      "NEXT OPEN HOUSE START TIME                                                                    0 non-null float64\n",
      "NEXT OPEN HOUSE END TIME                                                                      0 non-null float64\n",
      "URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)    2450 non-null object\n",
      "SOURCE                                                                                        1551 non-null object\n",
      "MLS#                                                                                          965 non-null object\n",
      "FAVORITE                                                                                      2450 non-null object\n",
      "INTERESTED                                                                                    2450 non-null object\n",
      "LATITUDE                                                                                      2450 non-null float64\n",
      "LONGITUDE                                                                                     2450 non-null float64\n",
      "dtypes: float64(14), object(13)\n",
      "memory usage: 516.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the rows where the columns you are going to use are nan values. Then split into train/test using 80/20 allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=['NEXT OPEN HOUSE START TIME','NEXT OPEN HOUSE END TIME','SOURCE','LOCATION','HOA/MONTH',\n",
    "                       'INTERESTED','MLS#','URL (SEE http://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3.PRICE\n",
    "X = df3.drop(columns='PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn a multivariate regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall we can use the following code to learn a multiple regression model predicting 'price' based on the following features on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features = ['SQUARE FEET', 'BEDS', 'BATHS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset traing_data and test_data using example_features and column['PRICE'] and store them into train_input, train_price, test_input, and test_price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train[example_features]\n",
    "train_price = y_train\n",
    "test_input = X_test[example_features]\n",
    "test_price = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a multivariate regression model using LinearRegression in sklearn.linear_model on train_data using train_input and train_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(train_input,train_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function that prints outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function of printing outcomes using coefficients, intercept and input_features\n",
    "def print_outcome(coefficients,intercept,input_features):\n",
    "    for x in range(len(input_features)):\n",
    "        print('The coefficient for {} is {}'.format(input_features[x],coefficients[x]))\n",
    "    print('The intercept is {}'.format(intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print out the coefficient and intercept of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for SQUARE FEET is 847.5870111405366\n",
      "The coefficient for BEDS is 61498.95517570657\n",
      "The coefficient for BATHS is -83887.77288419777\n",
      "The intercept is 33494.332950558746\n"
     ]
    }
   ],
   "source": [
    "print_outcome(regressor.coef_,regressor.intercept_,example_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a model is built we can use the .predict() function to find the predicted values for data we pass. For example using the example model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2214685.2324394668\n"
     ]
    }
   ],
   "source": [
    "example_predictions = regressor.predict(train_input)\n",
    "print(example_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can make predictions given the model, let's write a function to compute the RSS of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function of calculating RSS using model, data, outcome as input and return RSS\n",
    "def get_residual_sum_of_squares(model, data, outcome):\n",
    "    predictions = model.predict(data)\n",
    "    residuals = predictions - outcome\n",
    "    residuals_sum = residuals.sum()\n",
    "    RSS = residuals_sum ** 2\n",
    "    return(RSS)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function to calculate RSS for train_data and test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7956556380704924e-15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor,train_input,train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12442730951891.396"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor,test_input,test_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models with different features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a model_1 using different set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_features=['SQUARE FEET', 'BEDS', 'BATHS','LOT SIZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train[model_1_features]\n",
    "train_price = y_train\n",
    "test_input = X_test[model_1_features]\n",
    "test_price = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor2.fit(train_input,train_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print out the coefficient and intercept of model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for SQUARE FEET is 847.5025061844938\n",
      "The coefficient for BEDS is 61531.00590854499\n",
      "The coefficient for BATHS is -83882.13202245435\n",
      "The coefficient for LOT SIZE is 0.01463020890968282\n",
      "The intercept is 33381.66187558905\n"
     ]
    }
   ],
   "source": [
    "print_outcome(regressor2.coef_,regressor2.intercept_,model_1_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RSS for model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.806255641895632e-18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor2,train_input,train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12475333304287.207"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor2,test_input,test_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we often think of multiple regression as including multiple different features (e.g. # of bedrooms, squarefeet, and # of bathrooms) but we can also consider transformations of existing features e.g. the log of the squarefeet or even \"interaction\" features such as the product of bedrooms and bathrooms.\n",
    "\n",
    "You will use the logarithm function to create a new feature. so first you should import it from the math library.\n",
    "\n",
    "Next create the following 4 new features as column in both TEST and TRAIN data:\n",
    "* BEDS_squared = BEDS\\*BEDS\n",
    "* BED_BATH = BEDS\\*BATHS\n",
    "* log_SQFT = log(SQUARE FEET)\n",
    "* lat_plus_long = LATITUDE + LONGITUDE\n",
    "\n",
    "Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this feature will mostly affect houses with many bedrooms.\n",
    "bedrooms times bathrooms gives what's called an \"interaction\" feature. It is large when both of them are large.\n",
    "Taking the log of squarefeet has the effect of bringing large values closer together and spreading out small values.\n",
    "Adding latitude to longitude is totally non-sensical but we will do it anyway (you'll see why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['BEDS_squared'] = X['BEDS'] * X['BEDS']\n",
    "X['BED_BATH'] = X['BEDS'] * X['BATHS']\n",
    "X['lat_plus_long'] = X['LATITUDE'] + X['LONGITUDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus = []\n",
    "for x in X['SQUARE FEET']:\n",
    "    d = log(x)\n",
    "    plus.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['log_SQFT'] = plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build model_2 with more features than model_1: model_2_features=model_1_features+ ['BED_BATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_features = ['SQUARE FEET', 'BEDS', 'BATHS','LOT SIZE','BED_BATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train[model_2_features]\n",
    "train_price = y_train\n",
    "test_input = X_test[model_2_features]\n",
    "test_price = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor3.fit(train_input,train_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print out the coefficient and intercept of model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for SQUARE FEET is 815.8580848670385\n",
      "The coefficient for BEDS is 30073.764989576193\n",
      "The coefficient for BATHS is -142196.8235527953\n",
      "The coefficient for LOT SIZE is -0.07282153991256131\n",
      "The coefficient for BED_BATH is 18494.57928508887\n",
      "The intercept is 158625.58340264368\n"
     ]
    }
   ],
   "source": [
    "print_outcome(regressor3.coef_,regressor3.intercept_,model_2_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RSS for model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.501012394024343e-15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor3,train_input,train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365484301955831.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor3,test_input,test_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build model_3 with more features than model_2: model_3_features = model_2_features + ['BEDS_squared', 'log_SQFT', 'lat_plus_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_features = ['SQUARE FEET', 'BEDS', 'BATHS','LOT SIZE','BED_BATH','BEDS_squared', 'log_SQFT', 'lat_plus_long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = X_train[model_3_features]\n",
    "train_price = y_train\n",
    "test_input = X_test[model_3_features]\n",
    "test_price = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor4 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor4.fit(train_input,train_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print out the coefficient and intercept of model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient for SQUARE FEET is 286.0700915608937\n",
      "The coefficient for BEDS is 321056.47086781455\n",
      "The coefficient for BATHS is -271412.8976039463\n",
      "The coefficient for LOT SIZE is -1.0130818878731012\n",
      "The coefficient for BED_BATH is 91698.21875942852\n",
      "The coefficient for BEDS_squared is -72017.82329918582\n",
      "The coefficient for log_SQFT is 286.07009211113734\n",
      "The coefficient for lat_plus_long is -3352692.6621714337\n",
      "The intercept is -283633312.7175566\n"
     ]
    }
   ],
   "source": [
    "print_outcome(regressor4.coef_,regressor4.intercept_,model_3_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute RSS for model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3283064365386963e-10"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor4,train_input,train_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136917497619432.69"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_residual_sum_of_squares(regressor4,test_input,test_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate RSS for model_1, model_2, model_3 for train_data and test_data. What insights do you get from the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After calculating each model's RSS, the rss shows an increasing trend. I think this is strange. First, I believe\n",
    "# when considering more factors, the model will be more accurate. However, when considering more factors, the difference\n",
    "# between the predictions and the reality may gets bigger.\n",
    "# Therefore, I assume this is the reason why the RSS is increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will estimate multivariate regression weights via gradient descent.\n",
    "\n",
    "* Add a constant column of 1's to a dataframe to account for the intercept\n",
    "* Convert a dataframe into a Numpy array\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for all the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\".\n",
    "\n",
    "First we need to take the dataframe of our data and convert it into a 2D numpy array (also called a matrix).We can then use Panda's .as_matrix() to convert the dataframe into a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that will accept a dataframe, a list of feature names (e.g. ['SQUARE FEET', 'BEDS','BATHS']) and an target feature e.g. ('PRICE') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data, features, output):\n",
    "    data['Constant'] = 1\n",
    "    features = ['Constant'] + features\n",
    "    feature_matrix = data[features].values\n",
    "    output_array = data[output].values\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'SQUARE FEET' feature and a constant as our features and price as our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00e+00 1.19e+03]\n",
      "1500000.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(df, ['SQUARE FEET'], 'PRICE') # the [] around 'sqft_living' makes it a list\n",
    "print(example_features[0,:]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(example_output[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 2368.0] and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1000.0 = 1001.0 this is the dot product between these two arrays. If they're numpy arrays, we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.]) \n",
    "my_features = [1.0,1000.0]\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot() also works when dealing with a matrix and a vector. The predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features matrix and the weights vector. With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix,weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. The cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "2\\*error\\*[feature_i]\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative = 2 * np.dot(errors,feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the test code to test the feature derivative function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2682451712.0\n",
      "-2682451712.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(df3, ['SQUARE FEET'], 'PRICE') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print(derivative)\n",
    "print(-np.sum(example_output)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there exists some null-value, the resutls will be none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of increase and therefore the negative gradient is the direction of decrease and we're trying to minimize a cost function.\n",
    "\n",
    "The amount by which we move in the negative gradient direction is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "# recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    # make sure weights is a numpy array\n",
    "    weights = np.array(initial_weights)\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights) \n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        # initialize the gradient sum of squares to 0\n",
    "        gradient_sum_of_squares = 0\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): #loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:,i])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_of_squares = (derivative * derivative).sum()\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] = weights[i] - step_size * derivative\n",
    "            # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_of_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the gradient descent is designed for multivariate regression since the constant is now a feature we can use the gradient descent function to estimat the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(df3,train_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['SQUARE FEET']\n",
    "my_output = 'PRICE'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([0.0, 1.0])\n",
    "#step_size = 7e-12\n",
    "#tolerance = 2.5e7\n",
    "step_size = 7e-13\n",
    "tolerance = 1.0e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.33890829e-01 8.63240712e+02]\n"
     ]
    }
   ],
   "source": [
    "slope = regression_gradient_descent(simple_feature_matrix,output,initial_weights,step_size,tolerance)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in the closed form solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# create a numpy array of the test feature_matrix and test output\n",
    "simple_features = ['SQUARE FEET']\n",
    "my_output = 'PRICE'\n",
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4412887.054813535\n"
     ]
    }
   ],
   "source": [
    "# use predict_out function to calulate the prediction for test data.\n",
    "prediction = predict_output(test_simple_feature_matrix, slope)\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the RSS calualted from the test data.\n",
    "def residual_sum_of_squares(pred,test_output):\n",
    "    difference = pred - test_output\n",
    "    square_of_difference = difference * difference\n",
    "    RSS = square_of_difference.sum()\n",
    "    return RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279664929832036.88"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_sum_of_squares(prediction,test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Multivariate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend the code to use different multivariate features as the first half part of this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "train_data,test_data = train_test_split(df3,train_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# test out the gradient descent\n",
    "multi_features = ['SQUARE FEET','BEDS']\n",
    "my_output = 'PRICE'\n",
    "(multi_feature_matrix, output) = get_numpy_data(train_data, multi_features, my_output)\n",
    "initial_weights = np.array([-100000.0, 1.0,1.0])\n",
    "#step_size = 7e-12\n",
    "#tolerance = 2.5e7\n",
    "step_size = 7e-13\n",
    "tolerance = 1.0e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-0cd2f9fcf6ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mslope2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_feature_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslope2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-3f3aefba66f5>\u001b[0m in \u001b[0;36mregression_gradient_descent\u001b[0;34m(feature_matrix, output, initial_weights, step_size, tolerance)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Recall that feature_matrix[:, i] is the feature column associated with weights[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# compute the derivative for weight[i]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mderivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;31m# add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mgradient_sum_of_squares\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mderivative\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-9cea9307e4cb>\u001b[0m in \u001b[0;36mfeature_derivative\u001b[0;34m(errors, feature)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Assume that errors and feature are both numpy arrays of the same length (number of data points)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# compute twice the dot product of these vectors as 'derivative' and return the value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mderivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mderivative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slope2 = regression_gradient_descent(multi_feature_matrix,output,initial_weights,step_size,tolerance)\n",
    "print(slope2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try change the step_size and tolerance, how do the results change? (BE CAREFUL about the constant you picked, it may take a long time for the algorithm to converge.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liziwei/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "simple_features = ['SQUARE FEET']\n",
    "my_output = 'PRICE'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([0.0, 1.0])\n",
    "step_size = 7e-12\n",
    "tolerance = 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.90661781e-01 8.07844670e+02]\n"
     ]
    }
   ],
   "source": [
    "slope = regression_gradient_descent(simple_feature_matrix,output,initial_weights,step_size,tolerance)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients are almost the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4129702.5425454983\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_output(test_simple_feature_matrix, slope)\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286894808821128.75"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_sum_of_squares(prediction,test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From just one sample, I set the step size and tolerance are all bigger than the previous.\n",
    "# The Rss is bigger than the former.\n",
    "# If I change step size and tolerance are all smaller than the previous, the rss is still bigger than the former."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
